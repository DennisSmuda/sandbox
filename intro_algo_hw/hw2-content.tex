
\problem{4.1-2}

We saw that the solution of $T(n) = 2T(\lfloor\frac{n}{2}\rfloor) + n$ is $O(n\lg n)$. Show that the slution of this recurrence is also $\Omega(n \lg n)$.
Concolude that the solution is $\Theta(n \lg n)$.

\answer

Assume that $2^p \leq n < 2^{p-1}$, we have:

\begin{eqnarray*}
T(n) &=& 2T\left(\left\lfloor\frac{n}{2}\right\rfloor\right) + n\\
&=& 4T\left(\left\lfloor\frac{n}{4}\right\rfloor\right) + 2\times\left\lfloor\frac{n}{2}\right\rfloor + n\\
&\geq& 4T\left(\left\lfloor\frac{n}{4}\right\rfloor\right) + 2\times\left\lfloor\frac{2^p}{2}\right\rfloor + n\\
&=& 4T\left(\left\lfloor\frac{n}{4}\right\rfloor\right) + 2^p + n\\
&=& \cdots\\
&\geq& 2^k T\left(\left\lfloor\frac{n}{2^k}\right\rfloor\right) + 2^p \times (k - 1) + n\\
&=& 2^{k + 1} T\left(\left\lfloor\frac{n}{2^{k + 1}}\right\rfloor\right) + 2^k\times\left\lfloor\frac{n}{2^k}\right\rfloor  +2^p \times (k - 1) + n\\
&\geq& 2^{k + 1} T\left(\left\lfloor\frac{n}{2^{k + 1}}\right\rfloor\right) + 2^k\times\left\lfloor\frac{2^p}{2^k}\right\rfloor  +2^p \times (k - 1) + n\\
&=& 2^{k + 1} T\left(\left\lfloor\frac{n}{2^{k + 1}}\right\rfloor\right)  +2^p \times k + n\\
&=& \cdots\\
&\geq& 2^p T\left(\left\lfloor\frac{n}{2^p}\right\rfloor\right) + 2^p \times (p - 1) + n\\
&=& 2^p T(1) + 2^p \times (p - 1) + n\\
&>& 2n T(1) + 2n \lg n + n\\
&=& \Theta(n\lg n)
\end{eqnarray*}

Since $T(n)\geq \Theta(n\lg n)$, we have $T(n) = \Omega(n \lg n)$. Now we know that $T(n) = \Omega(n\lg n)$ and $T(n) = O(n \lg n)$, so $T(n) = \Theta(n\lg n)$.
\qed

\problem{4.2-1}

Use a recursion tree to determine a good asymptotic upper bound on the recurrence $T(n) = 3T(\lfloor\frac{n}{2}\rfloor) + n$. Use the substitution method to verify your answer.

\answer

Assume the answer is $T(n) = c\times n^{\lg3} - bn, 0 < b \leq 2, c > 0$. For $n > 3$, we have:

\begin{eqnarray*}
T(n) &=& 3T\left(\left\lfloor\frac{n}{2}\right\rfloor\right) + n\\
&=& 3c\times\left(\left\lfloor\frac{n}{2}\right\rfloor\right)^{\lg3} - 3b\left\lfloor \frac{n}{2}\right\rfloor + n\\
&\leq& 3c\times\left(\left\lfloor\frac{n}{2}\right\rfloor\right)^{\lg3} - 3b\times \frac{n -1}{2} + n\\
&=& 3c\times\left(\left\lfloor\frac{n}{2}\right\rfloor\right)^{\lg3} - \left(\frac{3b}{2} - 1\right)n + \frac{3b}{2}\\
&\leq& 3c \times \left(\frac{n}{2}\right)^{\lg3} - \left(\frac{3b}{2}- 1\right)n + n \text{\hspace{9pt}(note that $0 < b \leq 2$ and $n > 3$)}\\
&=& c\times n^{\lg3} - \left(\frac{3b}{2} - 2\right)n
\end{eqnarray*}

In order to make the following equation true, we only have to choose $c = 1, b = 2$:

$$c\times n^{\lg3} - bn \leq c\times n^{\lg3} - \left(\frac{3b}{2} - 2\right)n.$$

So now we have proved $T(n) = \Theta(n^{\lg 3}).$
\qed

\problem{4.3-1}

Use the master method to give tight asymptotic bounds for the following recurrences.

\begin{description}
\item[a. \hspace{9pt}] $T(n) = 4T(\lfloor\frac{n}{2}\rfloor) + n$.
\item[b. \hspace{9pt}] $T(n) = 4T(\lfloor\frac{n}{2}\rfloor) + n ^ 2$.
\item[c. \hspace{9pt}] $T(n) = 4T(\lfloor\frac{n}{2}\rfloor) + n ^ 3$.
\end{description}

\answer

\begin{description}
\item[a.\hspace{9pt}] $T(n) = \Theta(n^2)$.
\item[b.\hspace{9pt}] $T(n) = \Theta(n^2\lg n)$.
\item[c.\hspace{9pt}] $T(n) = \Theta(n^3)$.
\end{description}
\qed

\problem{5.1-3}

Suppose that you want to output 0 with probability $\frac{1}{2}$ and 1 with probability $\frac{1}{2}$. At your disposal is a procedure \textsc{Biased-Random}, that outputs
either 0 or 1. It outputs 1 with some probability $p$ and 0 with probability $1-p$, where $0 < p < 1$, but you do not know that $p$ is. Give an algorithm that uses
\textsc{Biased-Random} as a subroutine, and returns an unbiased answer, returning 0 with probility $\frac{1}{2}$ and 1 with probability $\frac{1}{2}$. What is the expected
running time of your algorithm as a function of $p$?

\answer

If we call \textsc{Biased-Random} twice, we could get one of $00, 01, 10, 11$. The probability of $01$ and $10$ are both $p(1-p)$, if we consider $01$ as $1$ and $10$ as $0$,
then we have could generate $1$ and $0$ with equal probability of $\frac{1}{2}$. And if we got $00$ or $11$, just keep calling \textsc{Biased-Random} until we reached 
$10$ or $01$. So we could use the following procedure:

\begin{algorithm}[H]
\caption{\textsc{Fairly-Random}}
\While{forever} {
  $a \leftarrow$ \textsc{Biased-Random}\\
  $b \leftarrow$ \textsc{Biased-Random}\\
  \If{$a = 0$ and $b = 1$}{
    \Return 1
  }\ElseIf {$a = 1$ and $b = 0$} {
    \Return 0
  }
}
\end{algorithm}

Now we could analyze the running time of the algorithm. On each round of the \textbf{while} loop, we have a probabily of $2p(1-p)$ to \textbf{return}. So by the property of
geometry distribution, the \textbf{while} loop will be executed $\frac{1}{2p(1-p)}$ times, which means the running time of the procedure is $\Theta\left(\frac{1}{2p(1-p)}\right)$.
\qed

\problem{5.3-4}

Professor Armstrong suggests the following procedure for generating a uniform random permutation:

\begin{algorithm}[H]
\caption{\textsc{Permute-By-Cycle}$(A)$}
$n \leftarrow length[A]$\\
$offset \leftarrow$\textsc{Random}$(1, n)$\\
\For{$i \leftarrow 1$ \KwTo $n$}{
  $dest \leftarrow i + offset$\\
  \If {$dest > n$} {
    $dest \leftarrow dest - n$
  }
  $B[dest] \leftarrow A[i]$
}
\Return $B$
\end{algorithm}

Show taht each element $A[i]$ has a $\frac{1}{n}$ probability of winding up in any particular position in $B$. Then show that Professor Armstrong is mistaken by showing
that the resulting permutation is not uniformly random.

\answer

The value of $offset$ is uniformly distributed in $[1, n]$, that means we have 
$$P(offset = k| k\in [1, n]) = \frac{1}{n}.$$

Let the indicator $X_{i, j}$ be the probability of ``$A[i]$ end up in $B[j]$''. We have:

\begin{eqnarray*}
X_{i, j} &=& P\left(offset = (j - i + n)\mod n\right)\\
&=& P(offset = k| k\in [1, n])\\
&=& \frac{1}{n}.
\end{eqnarray*}

Now we prove that the procedure cannot generate uniform permutation. Consider that case where $n>2$, we observe the permutation result on $A[1]$ and $A[2]$.
If the procedure generates uniform permutation, then there is $\frac{1}{2}$ probability that $A[2]$ ends up ahead of $A[1]$, in array $B$. But
 $A[2]$ ends up ahead of $A[1]$ only happens when $offset = n - 1$. The probability of $offset = n - 1$ is $\frac{1}{n} \neq \frac{1}{2}$. So the procedure
cannot generate uniform permutation.
\qed

\problem{5.4-2}

Suppose that balls are tossed into $b$ bins. Each toss is independent, and each ball is equally likely to end up in any bin. What is the expected number of ball tosses
before at least one of the bins contains two balls?

\answer

Let us consider the situation where in the first $k$ tosses, every bin contains at most $1$ ball. In this case, the first $k$ numbers will be a permutation on $b$.
And the whole sample space is $b^k$, since each time we could choose any one of the $b$ bins. So the probability that ``in the first $k - 1$ tosses, every bin contains
at most $1$ ball'' is $\frac{P^{k- 1}_b}{b^{k - 1}} = \frac{b!/(b-k + 1)!}{b^{k - 1}} = \frac{b!}{b^{k - 1}(b-k + 1)!}$. Thus we know that the probability that
``exactly in the $k$th toss, the target bin contains 2 balls for the first time'' is $\frac{k - 1}{b}\times\frac{b!}{b^{k - 1}(b - k + 1)!}$. So finally we have the expected number of ball tosses:

$$\sum_{k = 1}^{b + 1}\left(k\times\frac{k - 1}{b} \times \frac{b!}{b^{k - 1}(b - k + 1)!}\right) = \sum_{k = 1}^{b + 1} \left(\frac{k(k - 1)b!}{b^k(b - k + 1)!}\right).$$

On the other hand, this problem is similar to the ``Birthday paradox'', so by the same reasoning we know that the answer should be in the range $\Theta(\sqrt{b})$.
\qed


