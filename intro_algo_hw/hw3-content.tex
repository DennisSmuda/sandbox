
\problem{6.3-2}
Why do we want the loop index $i$ in line 2 of \textsc{Build-Max-Heap} to decrease from $\left\lfloor \frac{length[A]}{2}\right\rfloor$ to $1$ rather than increase from $1$
to $\left\lfloor \frac{length[A]}{2}\right\rfloor$?

\begin{algorithm}[H]
\caption{\textsc{Build-Max-Heap}$(A)$}
$heap$-$size[A]\leftarrow length[A]$\\
\For{$i \leftarrow \left\lfloor\frac{length[A]}{2}\right\rfloor$ \textnormal{\textbf{downto}} $1$} {
  \textsc{Max-Heapify}$(A, i)$
}
\end{algorithm}

\answer

This is because we must make sure that the smaller subtrees are changed to heaps first, so that the algorithm could build bigger subtrees correctly. If we increase the index $i$ from $1$ to
$\left\lfloor\frac{length[A]}{2}\right\rfloor$, the heap property cannot be correctly preserved.
\qed

\problem{6.5-7}
The operation \textsc{Heap-Delete}$(A, i)$ deletes the item in node $i$ from heap $A$. Give an implementation of \textsc{Heap-Delete} that runs in $O(\lg n)$ time for an $n$-element
max-heap.

\answer

The implementation is given below. Since both \textsc{Max-Heapify}$(A, i)$ and \textsc{Heap-Increase-Key}$(A, i, key)$ runs in $O(\lg n)$ time, \textsc{Heap-Delete}$(A, i)$ also runs in $O(\lg n)$.

\begin{algorithm}[H]
\caption{\textsc{Heap-Delete}$(A, i)$}
$n \leftarrow heap$-$size[A]$\\
$heap$-$size[A] \leftarrow heap$-$size[A] - 1$\\
\If{$A[i] < A[n]$}{
  \textsc{Heap-Increase-Key}$(A, i, A[n])$\\
}\Else{
  $A[i] \leftarrow A[n]$\\
  \textsc{Max-Heapify}$(A, i)$\\
}
\end{algorithm}
\qed

\problem{7-1 Hoare partition correctness}
The version of \textsc{Partition} given in this chapter is not the original partitioning algorithm. Here is the original parition algorithm, which is due to T.Hoare:

\begin{algorithm}[H]
\caption{\textsc{Hoare-Partition}(A, p, r)}
$x \leftarrow A[p]$\\
$i \leftarrow p - 1$\\
$j \leftarrow r + 1$\\
\While{$true$}{
  \Repeat{$A[j] \leq x$}{
    $j \leftarrow j - 1$\\
  }
  \Repeat{$A[i] \geq x$}{
    $i \leftarrow i + 1$\\
  }
  \If{$i < j$}{
    exchange $A[i] \leftrightarrow A[j]$
  }\Else{
    \Return $j$
  }
}
\end{algorithm}

\begin{description}
\item[a. \hspace{9pt}] Demonstrate the operation of \textsc{Hoare-Partition} on the array $A=\langle13, 19, 9, 5, 12, 8, 7, 4, 11,\\ 2, 6, 21\rangle$, showing the values of
the array and auxiliary values after each iteration of the \textbf{while} loop in lines $4-11$.\\

\end{description}
The next three questions ask you to give a careful argument that the procedure \textsc{Hoare-Partition} is correct. Prove the following:

\begin{description}
\item[b. \hspace{9pt}] The indices $i$ and $j$ are such that we never access an element of $A$ outside the subarray $A[p\ldots r]$.

\item[c. \hspace{9pt}] When \textsc{Hoare-Partition} terminates, it returns a value $j$ such that $p\leq j < r$.

\item[d. \hspace{9pt}] Every element of $A[p\ldots j]$ is less than or equal to every element of $A[j + 1\ldots r]$ when \textsc{Hoare-Partition} terminates.
\end{description}

The \textsc{Partition} procedure shown below separates the pivot value (originally in $A[r]$) from the two partitions it forms. The \textsc{Hoare-Partition} procedure,
on the other hand, always places the pivot value (originally in $A[p]$) into one of the two paritions $A[p\ldots j]$ and $A[j + 1\ldots r]$. Since $p\leq j < r$, this
split is always nontrivial.

\begin{algorithm}[H]
\caption{\textsc{Partition}(A, p, r)}
$x\leftarrow A[r]$\\
$i \leftarrow p - 1$\\
\For{$j \leftarrow p$ \KwTo $r-1$}{
  \If{$A[j] \leq x$} {
    $i \leftarrow i + 1$\\
    exchange $A[i] \leftrightarrow A[j]$\\
  }
}
exchange $A[i + 1]\leftrightarrow A[r]$\\
\Return {$i + 1$}
\end{algorithm}

\begin{description}
\item[e. \hspace{9pt}] Rewrite the \textsc{Quicksort} procedure to use \textsc{Hoare-Partition}.
\end{description}

\answer

\begin{description}
\item[a. \hspace{9pt}] The iteration is shown in the following table:

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Loop No. & $A$ & $i$ & $j$\\\hline
1 & $\langle 6, 19, 9, 5, 12, 8, 7, 4, 11, 2, 13, 21\rangle$ & 1 & 11\\\hline
2 & $\langle 6, 2, 9, 5, 12, 8, 7, 4, 11, 19, 13, 21\rangle$ & 2 & 10\\\hline
3 & $\langle 6, 2, 9, 5, 12, 8, 7, 4, 11, 19, 13, 21\rangle$ & 10 & 9\\\hline
\end{tabular}
\end{center}

\item[b. \hspace{9pt}] First of all, $j$ was given initial value $r + 1$, and it is decreased before the access of $A[j]$, so $j\leq r$ when $j$ is used as an index to $A$.
Similarly we have $i \geq p$.

Suppose that when the procedure \textbf{return}s, there is a $k$ such that $j < k < i$. Since the \textbf{repeat} statement of lines $5 \sim 7$ halts only when $A[j] \leq x$, 
we know that $A[k] > x$. Similarly, the \textbf{repeat} statement of lines $8 \sim 10$ halts only when $A[j] \geq x$, which requires $A[k] < x$. From this contradiction we knows
that the $k$ does not exist, which means $j \geq i - 1$.

On each round of the \textbf{while} loop, line 6 and line 9 are both executed at least once. If the \textbf{while} loop is executed more than once, we have $j \leq r - 1$ and
$i \geq p + 1$. With the fact that $j \geq i -1$, it is trivial to prove that  $p \leq i \leq r$ and $p \leq j \leq r$.


Now we consider the case when the \textbf{while} loop is executed only once. The \textbf{repeat} statement of lines $5 \sim 7$ halts when $A[j] \leq x$. With the fact that $A[p] = x$,
we have $j \geq p$. And the \textbf{repeat} statement of lines $8 \sim 10$ will halt with $i = p$. Now we have proved that under all cases, $p \leq i \leq r$ and $p \leq j \leq r$, 
so we never access an element of $A$ outside $A[p\ldots r]$.

\item[c. \hspace{9pt}] The original question should add another requirement that $p < r$. We have already proved that $p \leq j \leq r$. Suppose the procedure returned $j = r$, then
we know that the \textbf{while} loop is executed only once (in each \textbf{while} loop, $j$ is decreased at least by 1). And we know that on the first round of the \textbf{while}
loop, the \textbf{repeat} statement of lines $8 \sim 10$ will halt with $i = p$. The \textbf{return} statement will be reached only when $i \geq j$, that is, $p \geq r $. Now we have
a contradiction here, which means $j \neq r$, so the procedure returns $p \leq j < r$.

\item[d. \hspace{9pt}] We prove the invariant that ``after line 10, every element in $A[p \ldots i - 1]$ is less than or equal to $x$, and every element in $A[j + 1 \ldots r]$ is greater than
or equal to $x$''.

Before the first round of the \textbf{while} loop, this invariant is true, since there is no element in the subarrays. Suppose the invariant is true before the $k$th round, then in the $k$th
round, the \textbf{repeat} statement in lines $5 \sim 7$ decrease $j$ until $A[j] \leq x$, so it is still true that any element in $A[j + 1 \ldots r]$ is greater than or equal to $x$.
Similarly we know that any element in $A[p \ldots i - 1]$ is less than or equal to $x$. Lines $11\sim 14$ does not change the value of $i$ and $j$, so $i$ and $j$ remains unchanged until
the $(k + 1)$th loop. By mathematical induction we know that the invariant is true.

The procedure returns only when $i \geq j$, and we have proved $j \geq i - 1$ in question (c), so we have either $i = j$ or $i = j + 1$. If $i = j$, since $A[i] \geq x$ and $A[j] \leq x$, 
we have $A[i] = A[j] = x$, so every element in $A[p \ldots j]$ is less than or equal to $x$, and every element in $A[j + 1 \ldots r]$ is greater than or equal to $x$. If $i = j + 1$,
we have the same conclusion. Thus the statement of question (d) is proved.

\item[e. \hspace{9pt}] The algoritm is given below.

\end{description}
\begin{algorithm}[H]
\caption{\textsc{Hoare-Quicksort}(A, p, r)}
\If{$p \leq r$}{
  \Return
}\Else{
  $j \leftarrow$\textsc{Hoare-Partition}$(A, p, r)$\\
  \textsc{Hoare-Quicksort}$(A, p, j)$\\
  \textsc{Hoare-Quicksort}$(A, j + 1, r)$
}
\end{algorithm}
\qed

\problem{7-3 Stooge sort}
Professors Howard, Fine, and Howard have proposed the following ``elegant'' sorting algorithm:

\begin{algorithm}[H]
\caption{\textsc{Stooge-Sort}$(A, i, j)$}
\If{$A[i] > A[j]$}{
  exchange $A[i] \leftrightarrow A[j]$\\
}
\If{$i + 1 \geq j$}{
  \Return
}
$k\leftarrow \left\lfloor\frac{j - i + 1}{3}\right\rfloor$\tcp*[r]{Round down.}
\textsc{Stooge-Sort}$(A, i, j - k)$\tcp*[r]{First two-thirds.}
\textsc{Stooge-Sort}$(A, i +k, j)$\tcp*[r]{Last two-thirds.}
\textsc{Stooge-Sort}$(A, i, j - k)$\tcp*[r]{First two-thrids again.}
\end{algorithm}

\begin{description}
\item[a. \hspace{9pt}] Argue that, if $n = length[A]$, then \textsc{Stooge-Sort}$(A, 1, length[A])$ correctly sorts the input array $A[1\ldots n]$.

\item[b. \hspace{9pt}] Give a recurrence for the worst-case running time of \textsc{Stooge-Sort} and a tight asymptotic ($\Theta$-notation) bound on the worst-case
running time.

\item[c. \hspace{9pt}] Compare the worst-case running time of \textsc{Stooge-Sort} with that of insert sort, merge sort, heapsort, and quicksort. Do the professors
deserve tenure?
\end{description}

\answer

\begin{description}
\item[a. \hspace{9pt}]

It is trivial to check that the algorithm is correct for $n = 1, 2, 3$. Suppose the algorithm is correct for $n \leq n_0, (n_0 \geq 3)$, now we prove that it is still correct for $n = n_0 + 1$.

We know that $k \geq 1$, so $A[i\ldots j - k]$ has less than $(n_0 + 1)$ elements. Since the algorithm is correct for $n \leq n_0$, $A[i \ldots j - k]$ is correctly sorted.
Suppose there is an element in $A[i \ldots j - k]$ that is larger than an element $x$ in $A[j - k + 1 \ldots j]$. Since $A[i \ldots j - k]$ is correctly sorted in line $8$, we know that 
$A[j - k]  > x$. Also, since $A[j -k + 1\ldots j]$ is correctly sorted in line $7$, we know that $A[j - k + 1] \leq x$. This leads to $A[j -k + 1] < A[j - k]$, however, $A[j - k + 1]$
and $A[j - k]$ should have been sorted in line $7$, this is a contradiciton. So we know that for $n = n_0 + 1$,  every element in $A[i \ldots j - k]$ is less than or equal to
$A[j -k +1 \ldots j]$, and both subarrays are correctly sorted, so the whole array $A$ is sorted. By mathematical induction, we have proved that the algorithm is correct for all $n$.

\item[b. \hspace{9pt}] The running time recurrence is

$$T(n) = 3 T\left(\frac{2n}{3}\right) + \Theta(1).$$

By Master Theorem, we have

$$T(n) = \Theta\left(n^{\log_{\frac{3}{2}}3}\right) \sim \Theta(n^{2.71}).$$

\item[c. \hspace{9pt}] The worst running time of \textsc{Insert-Sort} and \textsc{Quick-Sort} are both $\Theta(n^2)$, that of \textsc{Merge-sort} and \textsc{Heap-Sort}
are both $\Theta(n\lg n)$. Any of them has a much better running time than $\Theta(n^{2.71})$, so \textsc{Stooge-Sort} is not a very good sorting algorithm.

\end{description}
\qed


